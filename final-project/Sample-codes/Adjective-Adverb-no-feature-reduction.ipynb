{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CMUTweetTagger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    stopword_list=nltk.corpus.stopwords.words('english')\n",
    "    tokens = tweet_tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(file):\n",
    "    data = pd.read_csv(file, sep='\\t', names=[\"id\", \"polarity\", \"tweet\"])\n",
    "    data = data.drop_duplicates()\n",
    "    data['tweet']=data['tweet'].apply(remove_stopwords)\n",
    "    data[\"tweet\"] = data[\"tweet\"].str.lower() # lowercase\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmu_tagger(only_tweet_data):\n",
    "    return CMUTweetTagger.runtagger_parse(only_tweet_data.values, run_tagger_cmd=\"java -XX:ParallelGCThreads=2 -Xmx500m -jar ./ark-tweet-nlp-0.3.2/ark-tweet-nlp-0.3.2.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_word_dict(only_tweet_data):\n",
    "    pos_count = get_cmu_tagger(only_tweet_data)\n",
    "    result = []\n",
    "    adj_words = dict()\n",
    "    for sentence in pos_count:\n",
    "        for word_tuple in sentence:\n",
    "            if word_tuple[1] == 'A': # 'R' is adverb\n",
    "                if word_tuple[0] in adj_words.keys():\n",
    "                    adj_words[word_tuple[0]] += 1\n",
    "                else:\n",
    "                    adj_words[word_tuple[0]] = 1\n",
    "    return adj_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_feature_array(only_tweet_data):\n",
    "    adj_word_dict = get_adj_word_dict(only_tweet_data)\n",
    "    prune_features = []\n",
    "    for key, value in adj_word_dict.items():\n",
    "        if (value >= 0): \n",
    "            prune_features.append(key)\n",
    "    return prune_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_word_dict(only_tweet_data):\n",
    "    pos_count = get_cmu_tagger(only_tweet_data)\n",
    "    result = []\n",
    "    adv_words = dict()\n",
    "    for sentence in pos_count:\n",
    "        for word_tuple in sentence:\n",
    "            if word_tuple[1] == 'R': # 'R' is adverb\n",
    "                if word_tuple[0] in adv_words.keys():\n",
    "                    adv_words[word_tuple[0]] += 1\n",
    "                else:\n",
    "                    adv_words[word_tuple[0]] = 1\n",
    "    return adv_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv_feature_array(only_tweet_data):\n",
    "    adv_word_dict = get_adv_word_dict(only_tweet_data)\n",
    "    prune_features = []\n",
    "    for key, value in adv_word_dict.items():\n",
    "        if (value >= 0): \n",
    "            prune_features.append(key)\n",
    "    return prune_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_array(only_tweet_data):\n",
    "    return get_adj_feature_array(only_tweet_data) + get_adv_feature_array(only_tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(only_tweet_data, features_array):\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    feature_result = []\n",
    "    for tweet in only_tweet_data:\n",
    "        tokens = tweet_tokenizer.tokenize(tweet)\n",
    "        \n",
    "        token_dict = dict()\n",
    "        tweet_arr = []\n",
    "        for token in tokens:\n",
    "            if token in token_dict.keys():\n",
    "                token_dict[token] += 1\n",
    "            else:\n",
    "                token_dict[token] = 1\n",
    "\n",
    "        for feature in features_array:\n",
    "            if feature in token_dict.keys():\n",
    "                tweet_arr.append(token_dict[feature])\n",
    "            else:\n",
    "                tweet_arr.append(0)\n",
    "        feature_result.append(tweet_arr)\n",
    "    return feature_result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train labels:  [0 1 2 ... 0 2 1]\n",
      "train features: [[-8.03556375e-03 -8.03556375e-03 -1.60726843e-02 ... -8.03556375e-03\n",
      "  -8.03556375e-03 -8.03556375e-03]\n",
      " [ 1.24446776e+02  1.24446776e+02  6.22173609e+01 ... -8.03556375e-03\n",
      "  -8.03556375e-03 -8.03556375e-03]\n",
      " [-8.03556375e-03 -8.03556375e-03 -1.60726843e-02 ... -8.03556375e-03\n",
      "  -8.03556375e-03 -8.03556375e-03]\n",
      " ...\n",
      " [-8.03556375e-03 -8.03556375e-03 -1.60726843e-02 ... -8.03556375e-03\n",
      "  -8.03556375e-03 -8.03556375e-03]\n",
      " [-8.03556375e-03 -8.03556375e-03 -1.60726843e-02 ... -8.03556375e-03\n",
      "  -8.03556375e-03 -8.03556375e-03]\n",
      " [-8.03556375e-03 -8.03556375e-03 -1.60726843e-02 ... -8.03556375e-03\n",
      "  -8.03556375e-03 -8.03556375e-03]]\n",
      "train labels shape:  (15488,)\n",
      "train features shape: (15488, 3249)\n"
     ]
    }
   ],
   "source": [
    "train_data = clean_df(\"./data/dataset/train_without_sarcasm\")\n",
    "only_tweet_train_data = train_data['tweet']\n",
    "features_array = get_feature_array(only_tweet_train_data)\n",
    "train_adj_feature = get_feature(only_tweet_train_data, features_array)\n",
    "\n",
    "train_labels = train_data.polarity\n",
    "result = []\n",
    "for x in train_labels:\n",
    "    if x == \"positive\":\n",
    "        result.append(2)\n",
    "    elif x == \"negative\":\n",
    "        result.append(1)\n",
    "    elif x == \"neutral\":\n",
    "        result.append(0)\n",
    "train_labels = np.array(result)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_adj_feature = scaler.fit_transform(train_adj_feature)\n",
    "\n",
    "train_features = np.array(train_adj_feature)\n",
    "\n",
    "\n",
    "print(\"train labels: \", train_labels) \n",
    "print(\"train features:\", train_features) \n",
    "print(\"train labels shape: \", train_labels.shape) \n",
    "print(\"train features shape:\", train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev labels:  [2 2 0 ... 1 2 0]\n",
      "dev features: [[-0.06733396 -0.07902327 -0.05045046 ...  0.          0.\n",
      "  -0.08366348]\n",
      " [-0.06733396 -0.07902327 -0.05045046 ...  0.          0.\n",
      "  -0.08366348]\n",
      " [-0.06733396 -0.07902327 -0.05045046 ...  0.          0.\n",
      "  -0.08366348]\n",
      " ...\n",
      " [-0.06733396 -0.07902327 -0.05045046 ...  0.          0.\n",
      "  -0.08366348]\n",
      " [-0.06733396 -0.07902327 -0.05045046 ...  0.          0.\n",
      "  -0.08366348]\n",
      " [-0.06733396 -0.07902327 -0.05045046 ...  0.          0.\n",
      "  -0.08366348]]\n",
      "dev_labels shape:  (3545,)\n",
      "dev_features shape: (3545, 2113)\n"
     ]
    }
   ],
   "source": [
    "dev_data = clean_df(\"./data/dataset/twitter-2013test-A.txt\")\n",
    "only_tweet_dev_data = dev_data['tweet']\n",
    "features_array = get_feature_array(only_tweet_train_data)\n",
    "dev_adj_feature = get_feature(only_tweet_dev_data, features_array)\n",
    "\n",
    "dev_labels = dev_data.polarity\n",
    "result = []\n",
    "for x in dev_labels:\n",
    "    if x == \"positive\":\n",
    "        result.append(2)\n",
    "    elif x == \"negative\":\n",
    "        result.append(1)\n",
    "    elif x == \"neutral\":\n",
    "        result.append(0)\n",
    "dev_labels = np.array(result)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dev_adj_feature = scaler.fit_transform(dev_adj_feature)\n",
    "\n",
    "dev_features = np.array(dev_adj_feature)\n",
    "\n",
    "print(\"dev labels: \", dev_labels) \n",
    "print(\"dev features:\", dev_features) \n",
    "print(\"dev_labels shape: \", dev_labels.shape) \n",
    "print(\"dev_features shape:\", dev_features.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"no_feature_reduc_adg_adv_vector.txt\", \"w+\")\n",
    "for i in dev_adj_feature:\n",
    "    content = str(i)\n",
    "    file.write(content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev labels:  [0 0 1 ... 0 0 0]\n",
      "dev features: [[-0.07405714 -0.0652725  -0.02462576 ...  0.          0.\n",
      "  -0.07124705]\n",
      " [-0.07405714 -0.0652725  -0.02462576 ...  0.          0.\n",
      "  -0.07124705]\n",
      " [-0.07405714 -0.0652725  -0.02462576 ...  0.          0.\n",
      "  -0.07124705]\n",
      " ...\n",
      " [-0.07405714 -0.0652725  -0.02462576 ...  0.          0.\n",
      "  -0.07124705]\n",
      " [-0.07405714 -0.0652725  -0.02462576 ...  0.          0.\n",
      "  -0.07124705]\n",
      " [-0.07405714 -0.0652725  -0.02462576 ...  0.          0.\n",
      "  -0.07124705]]\n",
      "dev_labels shape:  (1650,)\n",
      "dev_features shape: (1650, 2113)\n"
     ]
    }
   ],
   "source": [
    "dev_data = clean_df(\"./data/dataset/twitter-2013dev-A.txt\")\n",
    "only_tweet_dev_data = dev_data['tweet']\n",
    "features_array = get_feature_array(only_tweet_train_data)\n",
    "dev_adj_feature = get_feature(only_tweet_dev_data, features_array)\n",
    "\n",
    "dev_labels = dev_data.polarity\n",
    "result = []\n",
    "for x in dev_labels:\n",
    "    if x == \"positive\":\n",
    "        result.append(2)\n",
    "    elif x == \"negative\":\n",
    "        result.append(1)\n",
    "    elif x == \"neutral\":\n",
    "        result.append(0)\n",
    "dev_labels = np.array(result)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dev_adj_feature = scaler.fit_transform(dev_adj_feature)\n",
    "\n",
    "dev_features = np.array(dev_adj_feature)\n",
    "\n",
    "print(\"dev labels: \", dev_labels) \n",
    "print(\"dev features:\", dev_features) \n",
    "print(\"dev_labels shape: \", dev_labels.shape) \n",
    "print(\"dev_features shape:\", dev_features.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Classification Report showing the per-class Precision, Recall and F1-score \n",
      "\n",
      "C=0.005 \n",
      "Negative weight = 3.14 \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.58      0.84      0.68       737\n",
      "    negative       0.61      0.23      0.33       340\n",
      "    positive       0.63      0.49      0.55       573\n",
      "\n",
      "    accuracy                           0.59      1650\n",
      "   macro avg       0.60      0.52      0.52      1650\n",
      "weighted avg       0.60      0.59      0.56      1650\n",
      "\n",
      "A Classification Report showing the per-class Precision, Recall and F1-score \n",
      "\n",
      "C=1 \n",
      "Negative weight = 3.14 \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.58      0.84      0.69       737\n",
      "    negative       0.60      0.26      0.36       340\n",
      "    positive       0.63      0.48      0.55       573\n",
      "\n",
      "    accuracy                           0.60      1650\n",
      "   macro avg       0.60      0.53      0.53      1650\n",
      "weighted avg       0.60      0.60      0.57      1650\n",
      "\n",
      "A Classification Report showing the per-class Precision, Recall and F1-score \n",
      "\n",
      "C=1 \n",
      "Negative weight = 3.14 \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.58      0.75      0.65       737\n",
      "    negative       0.39      0.41      0.40       340\n",
      "    positive       0.68      0.41      0.51       573\n",
      "\n",
      "    accuracy                           0.56      1650\n",
      "   macro avg       0.55      0.52      0.52      1650\n",
      "weighted avg       0.58      0.56      0.55      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = SVC(kernel='linear', C=0.005, probability=True)\n",
    "\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=0.005 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "sample_weight = np.array([3.14 if i == 1 else 1 for i in train_labels])\n",
    "\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "# clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev labels:  [2 2 0 ... 1 2 0]\n",
      "dev features: [[-0.06733396 -0.07902327 -0.05045046 ... -0.02375907  0.\n",
      "  -0.01679783]\n",
      " [-0.06733396 -0.07902327 -0.05045046 ... -0.02375907  0.\n",
      "  -0.01679783]\n",
      " [-0.06733396 -0.07902327 -0.05045046 ... -0.02375907  0.\n",
      "  -0.01679783]\n",
      " ...\n",
      " [-0.06733396 -0.07902327 -0.05045046 ... -0.02375907  0.\n",
      "  -0.01679783]\n",
      " [-0.06733396 -0.07902327 -0.05045046 ... -0.02375907  0.\n",
      "  -0.01679783]\n",
      " [-0.06733396 -0.07902327 -0.05045046 ... -0.02375907  0.\n",
      "  -0.01679783]]\n",
      "dev_labels shape:  (3545,)\n",
      "dev_features shape: (3545, 696)\n"
     ]
    }
   ],
   "source": [
    "dev_data = clean_df(\"./data/dataset/twitter-2013test-A.txt\")\n",
    "only_tweet_dev_data = dev_data['tweet']\n",
    "features_array = get_feature_array(only_tweet_train_data)\n",
    "dev_adj_feature = get_feature(only_tweet_dev_data, features_array)\n",
    "\n",
    "dev_labels = dev_data.polarity\n",
    "result = []\n",
    "for x in dev_labels:\n",
    "    if x == \"positive\":\n",
    "        result.append(2)\n",
    "    elif x == \"negative\":\n",
    "        result.append(1)\n",
    "    elif x == \"neutral\":\n",
    "        result.append(0)\n",
    "dev_labels = np.array(result)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "dev_adj_feature = scaler.fit_transform(dev_adj_feature)\n",
    "\n",
    "dev_features = np.array(dev_adj_feature)\n",
    "\n",
    "print(\"dev labels: \", dev_labels) \n",
    "print(\"dev features:\", dev_features) \n",
    "print(\"dev_labels shape: \", dev_labels.shape) \n",
    "print(\"dev_features shape:\", dev_features.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Classification Report showing the per-class Precision, Recall and F1-score \n",
      "\n",
      "C=0.005 \n",
      "Negative weight = 3.14 \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.58      0.84      0.68       737\n",
      "    negative       0.61      0.23      0.33       340\n",
      "    positive       0.63      0.49      0.55       573\n",
      "\n",
      "    accuracy                           0.59      1650\n",
      "   macro avg       0.60      0.52      0.52      1650\n",
      "weighted avg       0.60      0.59      0.56      1650\n",
      "\n",
      "A Classification Report showing the per-class Precision, Recall and F1-score \n",
      "\n",
      "C=1 \n",
      "Negative weight = 3.14 \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.58      0.84      0.69       737\n",
      "    negative       0.60      0.26      0.36       340\n",
      "    positive       0.63      0.48      0.55       573\n",
      "\n",
      "    accuracy                           0.60      1650\n",
      "   macro avg       0.60      0.53      0.53      1650\n",
      "weighted avg       0.60      0.60      0.57      1650\n",
      "\n",
      "A Classification Report showing the per-class Precision, Recall and F1-score \n",
      "\n",
      "C=1 \n",
      "Negative weight = 3.14 \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.58      0.75      0.65       737\n",
      "    negative       0.39      0.41      0.40       340\n",
      "    positive       0.68      0.41      0.51       573\n",
      "\n",
      "    accuracy                           0.56      1650\n",
      "   macro avg       0.55      0.52      0.52      1650\n",
      "weighted avg       0.58      0.56      0.55      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = SVC(kernel='linear', C=0.005, probability=True)\n",
    "\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=0.005 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "sample_weight = np.array([3.14 if i == 1 else 1 for i in train_labels])\n",
    "\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "# clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
