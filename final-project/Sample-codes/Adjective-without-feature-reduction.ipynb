{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CMUTweetTagger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    stopword_list=nltk.corpus.stopwords.words('english')\n",
    "    tokens = tweet_tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(file):\n",
    "    data = pd.read_csv(file, sep='\\t', names=[\"id\", \"polarity\", \"tweet\"])\n",
    "    data = data.drop_duplicates()\n",
    "    data['tweet']=data['tweet'].apply(remove_stopwords)\n",
    "    data[\"tweet\"] = data[\"tweet\"].str.lower() # lowercase\n",
    "    data = data.reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmu_tagger(only_tweet_data):\n",
    "    return CMUTweetTagger.runtagger_parse(only_tweet_data.values, run_tagger_cmd=\"java -XX:ParallelGCThreads=2 -Xmx500m -jar ./ark-tweet-nlp-0.3.2/ark-tweet-nlp-0.3.2.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_dict(only_tweet_data):\n",
    "    pos_count = get_cmu_tagger(only_tweet_data)\n",
    "    result = []\n",
    "    adj_words = dict()\n",
    "    for sentence in pos_count:\n",
    "        for word_tuple in sentence:\n",
    "            if word_tuple[1] == 'A': # 'R' is adverb\n",
    "                if word_tuple[0] in adj_words.keys():\n",
    "                    adj_words[word_tuple[0]] += 1\n",
    "                else:\n",
    "                    adj_words[word_tuple[0]] = 1\n",
    "    return adj_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_array(only_tweet_data):\n",
    "    word_dict = get_word_dict(only_tweet_data)\n",
    "    prune_features = []\n",
    "    for key, value in word_dict.items():\n",
    "        if (value > 0): \n",
    "            prune_features.append(key)\n",
    "    return prune_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(only_tweet_data, features_array):\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    feature_result = []\n",
    "    for tweet in only_tweet_data:\n",
    "        tokens = tweet_tokenizer.tokenize(tweet)\n",
    "        \n",
    "        token_dict = dict()\n",
    "        tweet_arr = []\n",
    "        for token in tokens:\n",
    "            if token in token_dict.keys():\n",
    "                token_dict[token] += 1\n",
    "            else:\n",
    "                token_dict[token] = 1\n",
    "\n",
    "        for feature in features_array:\n",
    "            if feature in token_dict.keys():\n",
    "                tweet_arr.append(token_dict[feature])\n",
    "            else:\n",
    "                tweet_arr.append(0)\n",
    "        feature_result.append(tweet_arr)\n",
    "    return feature_result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = clean_df(\"./data/dataset/twitter-2013train-A.txt\")\n",
    "only_tweet_train_data = train_data['tweet']\n",
    "features_array = get_feature_array(only_tweet_train_data)\n",
    "train_adj_feature = get_feature(only_tweet_train_data, features_array)\n",
    "\n",
    "train_labels = train_data.polarity\n",
    "result = []\n",
    "for x in train_labels:\n",
    "    if x == \"positive\":\n",
    "        result.append(2)\n",
    "    elif x == \"negative\":\n",
    "        result.append(1)\n",
    "    elif x == \"neutral\":\n",
    "        result.append(0)\n",
    "train_labels = np.array(result)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_adj_feature = scaler.fit_transform(train_adj_feature)\n",
    "\n",
    "train_features = np.array(train_adj_feature)\n",
    "\n",
    "print(\"train labels: \", train_labels) \n",
    "print(\"train features:\", train_features) \n",
    "print(\"train labels shape: \", train_labels.shape) \n",
    "print(\"train features shape:\", train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = clean_df(\"./data/dataset/twitter-2013test-A.txt\")\n",
    "only_tweet_dev_data = dev_data['tweet']\n",
    "features_array = get_feature_array(only_tweet_train_data)\n",
    "dev_adj_feature = get_feature(only_tweet_dev_data, features_array)\n",
    "\n",
    "dev_labels = dev_data.polarity\n",
    "result = []\n",
    "for x in dev_labels:\n",
    "    if x == \"positive\":\n",
    "        result.append(2)\n",
    "    elif x == \"negative\":\n",
    "        result.append(1)\n",
    "    elif x == \"neutral\":\n",
    "        result.append(0)\n",
    "dev_labels = np.array(result)\n",
    "scaler = StandardScaler()\n",
    "dev_adj_feature = scaler.fit_transform(dev_adj_feature)\n",
    "dev_features = np.array(dev_adj_feature)\n",
    "\n",
    "print(\"dev labels: \", dev_labels) \n",
    "print(\"dev features:\", dev_features) \n",
    "print(\"dev_labels shape: \", dev_labels.shape) \n",
    "print(\"dev_features shape:\", dev_features.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"adj_no_feature_reduction_vector.txt\", \"w+\")\n",
    "for i in dev_adj_feature:\n",
    "    content = str(i)\n",
    "    file.write(content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = SVC(kernel='linear', C=0.005, probability=True)\n",
    "\n",
    "sample_weight = np.array([3.14 if i == 1 else 1 for i in train_labels])\n",
    "\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=0.005 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "sample_weight = np.array([3.14 if i == 1 else 1 for i in train_labels])\n",
    "\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "# clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "clf = SVC(kernel='linear', C=0.005, probability=True)\n",
    "\n",
    "arr = []\n",
    "\n",
    "for i in train_labels:\n",
    "    if i == 1:\n",
    "        arr.append(3.14)\n",
    "    elif i == 2:\n",
    "        arr.append(1.25)\n",
    "    else:\n",
    "        arr.append(1)\n",
    "\n",
    "sample_weight = np.array(arr)\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=0.005 \\nNegative weight = 3.14 \\nPositive weight = 1.25 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "arr = []\n",
    "\n",
    "for i in train_labels:\n",
    "    if i == 1:\n",
    "        arr.append(3.14)\n",
    "    elif i == 2:\n",
    "        arr.append(1.25)\n",
    "    else:\n",
    "        arr.append(1)\n",
    "\n",
    "\n",
    "sample_weight = np.array(arr)\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNegative weight = 3.14 \\nPositive weight = 1.25 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNo weight\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=0.005, probability=True)\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=0.005 \\nNo weight\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "param_grid = {'C': [0.005, 1], \n",
    "              'kernel': ['linear','rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "grid.fit(train_features, train_labels)\n",
    "\n",
    "print(grid.best_params_)\n",
    "  \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(dev_features)\n",
    "  \n",
    "print(classification_report(dev_labels, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = clean_df(\"./data/dataset/twitter-2013dev-A.txt\")\n",
    "only_tweet_dev_data = dev_data['tweet']\n",
    "features_array = get_feature_array(only_tweet_train_data)\n",
    "dev_adj_feature = get_feature(only_tweet_dev_data, features_array)\n",
    "\n",
    "dev_labels = dev_data.polarity\n",
    "result = []\n",
    "for x in dev_labels:\n",
    "    if x == \"positive\":\n",
    "        result.append(2)\n",
    "    elif x == \"negative\":\n",
    "        result.append(1)\n",
    "    elif x == \"neutral\":\n",
    "        result.append(0)\n",
    "dev_labels = np.array(result)\n",
    "scaler = StandardScaler()\n",
    "dev_adj_feature = scaler.fit_transform(dev_adj_feature)\n",
    "dev_features = np.array(dev_adj_feature)\n",
    "\n",
    "print(\"dev labels: \", dev_labels) \n",
    "print(\"dev features:\", dev_features) \n",
    "print(\"dev_labels shape: \", dev_labels.shape) \n",
    "print(\"dev_features shape:\", dev_features.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = SVC(kernel='linear', C=0.005, probability=True)\n",
    "\n",
    "sample_weight = np.array([3.14 if i == 1 else 1 for i in train_labels])\n",
    "\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=0.005 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "sample_weight = np.array([3.14 if i == 1 else 1 for i in train_labels])\n",
    "\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNegative weight = 3.14 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=0.005, probability=True)\n",
    "\n",
    "arr = []\n",
    "\n",
    "for i in train_labels:\n",
    "    if i == 1:\n",
    "        arr.append(3.14)\n",
    "    elif i == 2:\n",
    "        arr.append(1.25)\n",
    "    else:\n",
    "        arr.append(1)\n",
    "\n",
    "\n",
    "sample_weight = np.array(arr)\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=0.005 \\nNegative weight = 3.14 \\nPositive weight = 1.25 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "arr = []\n",
    "\n",
    "for i in train_labels:\n",
    "    if i == 1:\n",
    "        arr.append(3.14)\n",
    "    elif i == 2:\n",
    "        arr.append(1.25)\n",
    "    else:\n",
    "        arr.append(1)\n",
    "\n",
    "\n",
    "sample_weight = np.array(arr)\n",
    "clf.fit(train_features, train_labels, sample_weight = sample_weight)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNegative weight = 3.14 \\nPositive weight = 1.25 \\n\\n\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=1 \\nNo weight\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C=0.005, probability=True)\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(dev_features)\n",
    "\n",
    "print(\"A Classification Report showing the per-class Precision, Recall and F1-score \\n\\nC=0.005 \\nNo weight\", metrics.classification_report(dev_labels, predictions,target_names=['neutral','negative','positive']))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "param_grid = {'C': [0.005, 1], \n",
    "              'kernel': ['linear','rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "grid.fit(train_features, train_labels)\n",
    "\n",
    "print(grid.best_params_)\n",
    "  \n",
    "print(grid.best_estimator_)\n",
    "\n",
    "grid_predictions = grid.predict(dev_features)\n",
    "  \n",
    "print(classification_report(dev_labels, grid_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
